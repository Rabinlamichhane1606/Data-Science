{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rabinlamichhane1606/Data-Science/blob/master/GunsClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "__3o5rTiegHc",
        "outputId": "7e90a459-69d6-47fa-a94f-12745225dfde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 177 images belonging to 3 classes.\n",
            "Found 141 validated image filenames belonging to 3 classes.\n",
            "Found 36 validated image filenames belonging to 3 classes.\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8s/step - accuracy: 0.5362 - loss: 1.3757 - val_accuracy: 0.5556 - val_loss: 1.2038\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7s/step - accuracy: 0.5936 - loss: 1.0788 - val_accuracy: 0.5556 - val_loss: 1.3252\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.6628 - loss: 0.9104 - val_accuracy: 0.5556 - val_loss: 1.0380\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 7s/step - accuracy: 0.6216 - loss: 0.8749 - val_accuracy: 0.5556 - val_loss: 1.0054\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7s/step - accuracy: 0.6606 - loss: 0.8377 - val_accuracy: 0.5556 - val_loss: 1.1519\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.6163 - loss: 0.9001 - val_accuracy: 0.5556 - val_loss: 0.9751\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7s/step - accuracy: 0.6841 - loss: 0.7736 - val_accuracy: 0.5556 - val_loss: 1.0796\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.7520 - loss: 0.6285 - val_accuracy: 0.4722 - val_loss: 1.0199\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.6458 - loss: 0.7534 - val_accuracy: 0.5556 - val_loss: 1.0181\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.5579 - loss: 0.9867\n",
            "Score for fold 1: compile_metrics of 55.56%\n",
            "Found 141 validated image filenames belonging to 3 classes.\n",
            "Found 36 validated image filenames belonging to 3 classes.\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8s/step - accuracy: 0.5199 - loss: 1.1310 - val_accuracy: 0.5556 - val_loss: 1.0271\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 9s/step - accuracy: 0.6124 - loss: 0.9942 - val_accuracy: 0.5556 - val_loss: 0.9773\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7s/step - accuracy: 0.6615 - loss: 0.8851 - val_accuracy: 0.5556 - val_loss: 0.9068\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.6735 - loss: 0.8261 - val_accuracy: 0.5556 - val_loss: 0.9002\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.6582 - loss: 0.8215 - val_accuracy: 0.5556 - val_loss: 0.8933\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 7s/step - accuracy: 0.6793 - loss: 0.7448 - val_accuracy: 0.5833 - val_loss: 0.9014\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8s/step - accuracy: 0.7147 - loss: 0.7555 - val_accuracy: 0.5556 - val_loss: 0.8883\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.6535 - loss: 0.8059 - val_accuracy: 0.5556 - val_loss: 0.9288\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.6531 - loss: 0.7907 - val_accuracy: 0.5833 - val_loss: 0.8354\n",
            "Epoch 10/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.7724 - loss: 0.7337 - val_accuracy: 0.5556 - val_loss: 0.8925\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5868 - loss: 0.8245\n",
            "Score for fold 2: compile_metrics of 58.33%\n",
            "Found 142 validated image filenames belonging to 3 classes.\n",
            "Found 35 validated image filenames belonging to 3 classes.\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7s/step - accuracy: 0.4013 - loss: 1.3820 - val_accuracy: 0.1429 - val_loss: 1.3013\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 8s/step - accuracy: 0.4037 - loss: 1.0874 - val_accuracy: 0.7143 - val_loss: 0.8571\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.5778 - loss: 1.1188 - val_accuracy: 0.6571 - val_loss: 0.8938\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.6280 - loss: 0.9170 - val_accuracy: 0.7143 - val_loss: 0.7512\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7s/step - accuracy: 0.6313 - loss: 0.8438 - val_accuracy: 0.7143 - val_loss: 0.7974\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.6350 - loss: 0.8922 - val_accuracy: 0.7143 - val_loss: 0.7216\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7s/step - accuracy: 0.5863 - loss: 0.8475 - val_accuracy: 0.7143 - val_loss: 0.7155\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 8s/step - accuracy: 0.6432 - loss: 0.8103 - val_accuracy: 0.7143 - val_loss: 0.7426\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8s/step - accuracy: 0.6363 - loss: 0.7879 - val_accuracy: 0.7143 - val_loss: 0.7205\n",
            "Epoch 10/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7s/step - accuracy: 0.6586 - loss: 0.8089 - val_accuracy: 0.7143 - val_loss: 0.7356\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 462ms/step - accuracy: 0.7054 - loss: 0.7263\n",
            "Score for fold 3: compile_metrics of 71.43%\n",
            "Found 142 validated image filenames belonging to 3 classes.\n",
            "Found 35 validated image filenames belonging to 3 classes.\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7s/step - accuracy: 0.4859 - loss: 1.3309 - val_accuracy: 0.6286 - val_loss: 1.0253\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6s/step - accuracy: 0.6140 - loss: 1.0438 - val_accuracy: 0.6000 - val_loss: 0.9610\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 7s/step - accuracy: 0.5668 - loss: 0.9396 - val_accuracy: 0.6286 - val_loss: 0.9422\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 6s/step - accuracy: 0.6543 - loss: 0.8429 - val_accuracy: 0.6286 - val_loss: 0.9409\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7s/step - accuracy: 0.5817 - loss: 0.8762 - val_accuracy: 0.6286 - val_loss: 0.8887\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8s/step - accuracy: 0.6198 - loss: 0.8199 - val_accuracy: 0.6286 - val_loss: 0.8817\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7s/step - accuracy: 0.6768 - loss: 0.7852 - val_accuracy: 0.6571 - val_loss: 0.8775\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 9s/step - accuracy: 0.6231 - loss: 0.8041 - val_accuracy: 0.6857 - val_loss: 0.8608\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7s/step - accuracy: 0.6164 - loss: 0.7836 - val_accuracy: 0.6286 - val_loss: 0.8487\n",
            "Epoch 10/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7s/step - accuracy: 0.6261 - loss: 0.8000 - val_accuracy: 0.6857 - val_loss: 0.8440\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 716ms/step - accuracy: 0.6759 - loss: 0.8584\n",
            "Score for fold 4: compile_metrics of 68.57%\n",
            "Found 142 validated image filenames belonging to 3 classes.\n",
            "Found 35 validated image filenames belonging to 3 classes.\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 8s/step - accuracy: 0.4986 - loss: 1.2004 - val_accuracy: 0.6286 - val_loss: 0.8684\n",
            "Epoch 2/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 7s/step - accuracy: 0.5962 - loss: 1.1124 - val_accuracy: 0.6286 - val_loss: 0.8154\n",
            "Epoch 3/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7s/step - accuracy: 0.6453 - loss: 0.9011 - val_accuracy: 0.6571 - val_loss: 0.9136\n",
            "Epoch 4/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 8s/step - accuracy: 0.5862 - loss: 0.9256 - val_accuracy: 0.6571 - val_loss: 0.7815\n",
            "Epoch 5/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7s/step - accuracy: 0.5991 - loss: 0.9040 - val_accuracy: 0.6571 - val_loss: 0.7775\n",
            "Epoch 6/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 8s/step - accuracy: 0.5911 - loss: 0.8577 - val_accuracy: 0.6571 - val_loss: 0.7636\n",
            "Epoch 7/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.6475 - loss: 0.7680 - val_accuracy: 0.6571 - val_loss: 0.7653\n",
            "Epoch 8/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 7s/step - accuracy: 0.6682 - loss: 0.8273 - val_accuracy: 0.6571 - val_loss: 0.7324\n",
            "Epoch 9/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7s/step - accuracy: 0.6001 - loss: 0.8062 - val_accuracy: 0.6571 - val_loss: 0.7555\n",
            "Epoch 10/10\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 7s/step - accuracy: 0.6588 - loss: 0.7519 - val_accuracy: 0.8286 - val_loss: 0.7744\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 481ms/step - accuracy: 0.6464 - loss: 0.7403\n",
            "Score for fold 5: compile_metrics of 65.71%\n",
            "Average accuracy over 5 folds: 63.92%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import Model\n",
        "import pandas as pd\n",
        "\n",
        "# Set the paths for the dataset\n",
        "train_data_dir = '/content/drive/MyDrive/Colab Notebooks/Guns_dataset/processed_dataset/train'\n",
        "\n",
        "# Function to create a ResNet50 model\n",
        "def create_resnet50_model(input_shape, num_classes):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # Freeze the layers of ResNet50 to prevent them from training initially\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Prepare the data generator for rescaling\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the dataset without shuffling, since we're doing it manually with KFold\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(224, 224),  # ResNet50 requires 224x224 input size\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Extract file paths and labels\n",
        "X = np.array(train_generator.filepaths)\n",
        "y = np.array(train_generator.classes)\n",
        "\n",
        "# Convert numerical labels to their string equivalents\n",
        "class_indices = train_generator.class_indices\n",
        "classes = {v: k for k, v in class_indices.items()}\n",
        "y_str = np.array([classes[i] for i in y])\n",
        "\n",
        "# Set up K-Fold Cross Validation\n",
        "k = 5\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize variables to store results\n",
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "\n",
        "# Perform K-Fold Cross-Validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    # Create the data generators for the current fold\n",
        "    train_generator_fold = datagen.flow_from_dataframe(\n",
        "        dataframe=pd.DataFrame({'filename': X[train_index], 'class': y_str[train_index]}),\n",
        "        directory=None,\n",
        "        x_col='filename',\n",
        "        y_col='class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator_fold = datagen.flow_from_dataframe(\n",
        "        dataframe=pd.DataFrame({'filename': X[val_index], 'class': y_str[val_index]}),\n",
        "        directory=None,\n",
        "        x_col='filename',\n",
        "        y_col='class',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # Create a new ResNet50 model for each fold\n",
        "    model = create_resnet50_model(input_shape=(224, 224, 3), num_classes=train_generator.num_classes)\n",
        "\n",
        "    # Train the model\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    history = model.fit(train_generator_fold, epochs=10, validation_data=val_generator_fold,\n",
        "                        callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)])\n",
        "\n",
        "    # Evaluate the model\n",
        "    scores = model.evaluate(val_generator_fold)\n",
        "    acc_per_fold.append(scores[1])\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[1]} of {scores[1] * 100:.2f}%')\n",
        "    fold_no += 1\n",
        "\n",
        "# Print the average accuracy\n",
        "print(f'Average accuracy over {k} folds: {np.mean(acc_per_fold) * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkWDgzSFfg_r",
        "outputId": "b8c282b2-f574-499c-d937-c5085185121c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLWPLrFrx5T7dQbrcjv06Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}